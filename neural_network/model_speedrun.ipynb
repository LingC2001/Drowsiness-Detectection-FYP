{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsinessData(Dataset):\n",
    "    def __init__(self,data, trn_val_tst, transform=None):\n",
    "        split_idx1 = int(data.shape[0]*0.6)\n",
    "        split_idx2 = int(data.shape[0]*0.8)\n",
    "        if trn_val_tst == 0:\n",
    "            #trainloader\n",
    "            self.X = data.iloc[0:split_idx1, 0:-3].to_numpy()\n",
    "            self.labels = data.iloc[0:split_idx1, -1].to_numpy()\n",
    "        elif trn_val_tst == 1:\n",
    "            #valloader\n",
    "            self.X = data.iloc[split_idx1:split_idx2, 0:-3].to_numpy()\n",
    "            self.labels = data.iloc[split_idx1:split_idx2, -1].to_numpy()\n",
    "        else:\n",
    "            #testloader\n",
    "            self.X = data.iloc[split_idx1:split_idx2, 0:-3].to_numpy()\n",
    "            self.labels = data.iloc[split_idx1:split_idx2, -1].to_numpy()\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "   \n",
    "        sample = self.X[idx,:]\n",
    "        labels = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"features_and_labels_30s.csv\")\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_set = DrowsinessData(data, trn_val_tst=0, transform=transforms.ToTensor()) \n",
    "val_set = DrowsinessData(data, trn_val_tst=1, transform=transforms.ToTensor())\n",
    "test_set = DrowsinessData(data, trn_val_tst=2, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 100 \n",
    "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validloader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "testloader =  DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_features = train_set.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should perform a single evaluation epoch, it WILL NOT be used to train our model\n",
    "def evaluate(model, device, loader, loss_fun):\n",
    "    #initialise counter\n",
    "    epoch_acc = 0\n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    #Set network in evaluation mode\n",
    "    #Layers like Dropout will be disabled\n",
    "    #Layers like Batchnorm will stop calculating running mean and standard deviation\n",
    "    #and use current stored values\n",
    "    #(More on these layer types soon!)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            #Forward pass of image through network\n",
    "            fx = model(x.to(device))\n",
    "            y = y.type(torch.LongTensor)\n",
    "            \n",
    "            #log the cumulative sum of the acc\n",
    "            epoch_acc += (fx.argmax(1) == y.to(device)).sum().item()\n",
    "            \n",
    "            #calculate the loss\n",
    "            loss = loss_fun(fx, y.to(device))\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "    \n",
    "    # Calculating the average loss per epoch\n",
    "    loss_per_epoch = total_loss/count\n",
    "    #return the accuracy from the epoch     \n",
    "    return epoch_acc*100 / len(loader.dataset), loss_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should perform a single training epoch using our training data\n",
    "def train(model, device, loader, optimizer, loss_fun, loss_logger):\n",
    "    \n",
    "    #Set Network in train mode\n",
    "    model.train()\n",
    "    \n",
    "    count = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        #Perform a single epoch of training on the input dataloader, logging the loss at every step \n",
    "        #Forward pass of image through network and get output\n",
    "        fx = model(x.to(device))\n",
    "        y = y.type(torch.LongTensor)\n",
    "\n",
    "        \n",
    "        #Calculate loss using loss function\n",
    "        loss = loss_fun(fx, y.to(device))\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "        #Zero Gradents\n",
    "        optimizer.zero_grad()\n",
    "        #Backpropagate Gradents\n",
    "        loss.backward()\n",
    "        #Do a single optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "    #log the loss PER EPOCH for plotting\n",
    "    loss_logger.append(total_loss/count)\n",
    "   \n",
    "    #return the logger array       \n",
    "    return loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsyNet(nn.Module):\n",
    "    def __init__(self, channels_in):\n",
    "        # calling the init function of the parent nn.Module\n",
    "        super(DrowsyNet, self).__init__()\n",
    "        \n",
    "        # defining the fully connected layers\n",
    "        print(channels_in)\n",
    "        self.fc1 = nn.Linear(int(channels_in), int(channels_in//1.5))\n",
    "        self.fc2 = nn.Linear(int(channels_in//1.5), int(channels_in//3))\n",
    "        self.fc3 = nn.Linear(int(channels_in//3), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passing it through fc layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "DrowsyNet(\n",
      "  (fc1): Linear(in_features=20, out_features=13, bias=True)\n",
      "  (fc2): Linear(in_features=13, out_features=6, bias=True)\n",
      "  (fc3): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n",
      "364 364\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')\n",
    "model = DrowsyNet(num_features).to(device)\n",
    "print(model)\n",
    "\n",
    "pytorch_total_params = sum([p.numel() for p in model.parameters()])\n",
    "pytorch_total_trainable_params = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "print(pytorch_total_params, pytorch_total_trainable_params)\n",
    "\n",
    "learning_rate =1e-4\n",
    "start_epoch = 0\n",
    "num_epochs = 100\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_fun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(1051, slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(1051, slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\School\\Drowsiness-Detection-FYP\\neural_network\\model_speedrun.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#This cell implements our training loop\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#call the training function and pass training dataloader etc\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     training_loss_logger \u001b[39m=\u001b[39m train(model, device, trainloader, optimizer, loss_fun, training_loss_logger)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m#call the evaluate function and pass the dataloader for both ailidation and training\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     train_acc, _ \u001b[39m=\u001b[39m evaluate(model, device, trainloader, loss_fun)\n",
      "\u001b[1;32md:\\School\\Drowsiness-Detection-FYP\\neural_network\\model_speedrun.ipynb Cell 8\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, device, loader, optimizer, loss_fun, loss_logger)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#Perform a single epoch of training on the input dataloader, logging the loss at every step \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m#Forward pass of image through network and get output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     fx \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32md:\\School\\Drowsiness-Detection-FYP\\neural_network\\model_speedrun.ipynb Cell 8\u001b[0m line \u001b[0;36mDrowsinessData.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX[idx,:]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/School/Drowsiness-Detection-FYP/neural_network/model_speedrun.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3629\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32md:\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (1051, slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "training_loss_logger = []\n",
    "validation_loss_logger = []\n",
    "\n",
    "training_acc_logger = []\n",
    "validation_acc_logger = []\n",
    "testing_acc_logger = []\n",
    "\n",
    "highest_val_acc = -math.inf\n",
    "\n",
    "\n",
    "#This cell implements our training loop\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    #call the training function and pass training dataloader etc\n",
    "    training_loss_logger = train(model, device, trainloader, optimizer, loss_fun, training_loss_logger)\n",
    "    \n",
    "    #call the evaluate function and pass the dataloader for both ailidation and training\n",
    "    train_acc, _ = evaluate(model, device, trainloader, loss_fun)\n",
    "    training_acc_logger.append(train_acc)\n",
    "    \n",
    "    valid_acc, valid_loss = evaluate(model, device, validloader, loss_fun)\n",
    "    validation_loss_logger.append(valid_loss)\n",
    "    validation_acc_logger.append(valid_acc)\n",
    "\n",
    "    test_acc, _ = evaluate(model, device, testloader, loss_fun)\n",
    "    testing_acc_logger.append(test_acc)\n",
    "\n",
    "    # Copying the model with the highest validation accuracy\n",
    "    if valid_acc > highest_val_acc:\n",
    "        highest_val_acc_epoch = epoch\n",
    "        highest_val_acc = valid_acc\n",
    "        highest_val_acc_model = deepcopy(model)\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Acc: {train_acc:05.2f}% | Val. Acc: {valid_acc:05.2f}% | Test Acc: {test_acc:05.2f}%')\n",
    "print(\"Training Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

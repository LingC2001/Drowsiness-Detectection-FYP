{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsinessData(Dataset):\n",
    "    def __init__(self,data, trn_val_tst, transform=None):\n",
    "\n",
    "        # split_idx1 = int(data.shape[0]*0.6)\n",
    "        # split_idx2 = int(data.shape[0]*0.8)\n",
    "        # if trn_val_tst == 0:\n",
    "        #     #trainloader\n",
    "        #     self.X = data.iloc[0:split_idx1, 0:-1].to_numpy()\n",
    "        #     self.labels = data.iloc[0:split_idx1, -1].to_numpy()\n",
    "        # elif trn_val_tst == 1:\n",
    "        #     #valloader\n",
    "        #     self.X = data.iloc[split_idx1:split_idx2, 0:-1].to_numpy()\n",
    "        #     self.labels = data.iloc[split_idx1:split_idx2, -1].to_numpy()\n",
    "        # else:\n",
    "        #     #testloader\n",
    "        #     self.X = data.iloc[split_idx1:split_idx2, 0:-1].to_numpy()\n",
    "        #     self.labels = data.iloc[split_idx1:split_idx2, -1].to_numpy()\n",
    "\n",
    "        self.X = data.iloc[:, 0:-1].to_numpy()\n",
    "        self.labels = data.iloc[:, -1].to_numpy()\n",
    "        self.labels[self.labels < 6.5] = 0\n",
    "        self.labels[self.labels >= 6.5] = 1\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = self.X[idx,:]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # if self.transform:\n",
    "        #     sample = self.transform(sample)\n",
    "        sample = torch.from_numpy(sample).type(torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(697, 31)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"../Features_and_Labels/30s/test_features_and_labels_30s.csv\")\n",
    "\n",
    "\n",
    "filter_features = {\n",
    "    \"mrmr\": {\n",
    "        \"30\": ['Sh_Ent1', 'MDF', 'bandPower(){}_2_beta', 'lf_hf_ratio', 'LZC(){}_1', 'MNF', 'sampEn(){}_2', 'PKF', 'ZC', 'csi', 'bandPower(){}_2_alpha', 'DFA(){}_2', 'Sh_Ent0', 'Sp_ent2', \n",
    "               'blinking_rate', 'LZC(){}_2', 'WENT', 'hjorthMobility(){}_2', 'bandPower(){}_1_beta', 'pnni_20', 'PFD(){}_1', 'hjorthComplexity(){}_2', 'bandPower(){}_2_theta', 'wave_ent2', \n",
    "               'lfnu', 'LOG', 'HFD(){}_2', 'pnni_50', 'bandPower(){}_1_alpha', 'sampEn(){}_1', 'kss']\n",
    "    },\n",
    "    \"kbest\": {\n",
    "        \"30\": ['bandPower(){}_1_alpha', 'bandPower(){}_1_beta', 'bandPower(){}_2_theta', 'bandPower(){}_2_alpha', 'bandPower(){}_2_beta', 'hjorthMobility(){}_1', 'hjorthMobility(){}_2', \n",
    "                'hjorthComplexity(){}_2', 'sampEn(){}_1', 'sampEn(){}_2', 'DFA(){}_2', 'PFD(){}_1', 'PFD(){}_2', 'LZC(){}_1', 'LZC(){}_2', 'Sh_Ent0', 'fuzzy0', 'Sp_ent2', 'wave_ent2', 'lf_hf_ratio', \n",
    "                'lfnu', 'csi', 'LOG', 'ZC', 'MYOP', 'MNF', 'MDF', 'PKF', 'WENT', 'blinking_rate', 'kss']\n",
    "    }\n",
    "}\n",
    "\n",
    "ttest_features = [\"bandPower(){}_0_theta\", \"bandPower(){}_0_alpha\", \"bandPower(){}_0_beta\",\t\"bandPower(){}_1_delta\", \"bandPower(){}_2_alpha\", \"bandPower(){}_2_beta\", \n",
    "                  \"hjorthActivity(){}_1\", \"hjorthActivity(){}_2\", \"hjorthMobility(){}_0\", \"hjorthMobility(){}_2\", \"hjorthComplexity(){}_0\",\t\"hjorthComplexity(){}_2\", \"sampEn(){}_2\", \n",
    "                  \"DFA(){}_0\", \"DFA(){}_2\", \"PFD(){}_2\", \"LZC(){}_0\", \"LZC(){}_1\",\t\"LZC(){}_2\", \"fuzzy0\", \"Sp_ent0\", \"EEG_kurt0\",\t\"Sp_ent1\",\t\"wave_ent1\", \"EEG_kurt1\", \"Multiscale2\", \n",
    "                  \"Sp_ent2\", \"wave_ent2\", \"EEG_mean2\", \"EEG_kurt2\", \"cvnni\",\t\"max_hr\", \"nni_20\",\t\"nni_50\", \"pnni_20\", \"pnni_50\",\t\"range_nni\", \"fuzzy\",\t\"sdsd\",\t\"std_hr\", \"lf\",\t\"hf\", \n",
    "                  \"lf_hf_ratio\", \"lfnu\", \"total_power\",\t\"vlf\",\t\"csi\",\t\"RMS\", \"IEMG\",\t\"MAV\",\t\"LOG\",\t\"ZC\", \"WAMP\", \"MNF\", \"MDF\",\t\"PKF\", \"WENT\", \"blinking_rate\",\t\"MAR_mean\",\t\"vtilt_mean\", \n",
    "                  \"htilt_std\", \"kss\"]\n",
    "\n",
    "test_data = test_data.loc[:, filter_features[\"kbest\"][\"30\"]]\n",
    "\n",
    "print(test_data.shape)\n",
    "\n",
    "test_set = DrowsinessData(test_data, trn_val_tst=2)\n",
    "\n",
    "batch_size = 100 \n",
    "\n",
    "testloader =  DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_features = test_set.X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsyNet(nn.Module):\n",
    "    def __init__(self, channels_in):\n",
    "        # calling the init function of the parent nn.Module\n",
    "        super(DrowsyNet, self).__init__()\n",
    "        \n",
    "        # defining the fully connected layers\n",
    "        print(channels_in)\n",
    "        self.fc1 = nn.Linear(int(channels_in), int(channels_in//1.5))\n",
    "        self.fc2 = nn.Linear(int(channels_in//1.5), int(channels_in//3))\n",
    "        self.fc3 = nn.Linear(int(channels_in//3), 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passing it through fc layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should perform a single evaluation epoch, it WILL NOT be used to train our model\n",
    "def evaluate(model, device, loader, loss_fun):\n",
    "    \n",
    "    #initialise counter\n",
    "    epoch_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    #Set network in evaluation mode\n",
    "    #Layers like Dropout will be disabled\n",
    "    #Layers like Batchnorm will stop calculating running mean and standard deviation\n",
    "    #and use current stored values\n",
    "    #(More on these layer types soon!)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            #Forward pass of image through network\n",
    "            fx = model(x.to(device))\n",
    "            y = y.type(torch.FloatTensor)\n",
    "            \n",
    "            #log the cumulative sum of the acc\n",
    "            epoch_acc += (np.round(fx.cpu().detach()) == y).sum()\n",
    "            total_count += y.shape[0]\n",
    "            \n",
    "            #calculate the loss\n",
    "            loss = loss_fun(fx, y.to(device))\n",
    "            total_loss += loss.item()\n",
    "    #return the accuracy from the epoch     \n",
    "    return epoch_acc / total_count, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "1.5684333592653275 1.2523710948697784 tensor(0.6829)\n"
     ]
    }
   ],
   "source": [
    "GPU_indx = 0\n",
    "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')\n",
    "model = DrowsyNet(num_features).to(device)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "model.load_state_dict(torch.load(\"D:/School/Drowsiness-Detection-FYP/neural_network/classification/best_model.pt\"))\n",
    "\n",
    "test_acc, test_loss = evaluate(model, device, testloader, loss_fun)\n",
    "\n",
    "print(test_loss, np.sqrt(test_loss), test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.20785111, 0.23562431, 0.25171882, 0.33281526, 0.42931992, 0.40668005, 0.367253, 0.18305598, 0.23002392, 0.1774813, 0.38265204, 0.43299174, 0.29349712, 0.3254166, 0.22907071, 0.24896544, 0.31665498, 0.3447801, 0.36418322, 0.4709545, 0.4141414, 0.38260272, 0.42419058, 0.4175412, 0.41845572, 0.41780436, 0.34205386, 0.42831722, 0.5625757, 0.45461074, 0.42596695, 0.6105818, 0.6083659, 0.6104965, 0.5412599, 0.42155996, 0.46122473, 0.4571895, 0.6495836, 0.6320116, 0.67821896, 0.48586696, 0.42719284, 0.39624658, 0.43411303, 0.62346107, 0.59960854, 0.47541487, 0.44338667, 0.44473973, 0.42433476, 0.39880008, 0.34172672, 0.53707206, 0.48703828, 0.38717732, 0.38375202, 0.34749085, 0.3883361, 0.5879831, 0.5395243, 0.422196, 0.34500343, 0.36815664, 0.32543734, 0.4059523, 0.41244394, 0.38579062, 0.42721546, 0.43778983, 0.4764894, 0.42966864, 0.37090495, 0.07550483, 0.0649423, 0.3096425, 0.059000067, 0.25163934, 0.29184023, 0.38725618, 0.3594291, 0.5592826, 0.3493879, 0.33401003, 0.3762579, 0.33774695, 0.33430925, 0.36928186, 0.38155246, 0.37767163, 0.38131878, 0.8200872, 0.3644729, 0.5361016, 0.63955414, 0.32539096, 0.80154586, 0.17670864, 0.41158113, 0.20375104, 0.19871598, 0.19543059, 0.76734984, 0.26245096, 0.0041001374, 0.4973453, 0.60043323, 0.2255183, 0.60332775, 0.2644834, 0.16574855, 0.21080898, 0.16762197, 0.34242508, 0.21463898, 0.2335767, 0.21032088, 0.23057835, 0.1613216, 0.64092684, 0.67546695, 0.13206413, 0.22850016, 0.31635886, 0.23929034, 0.21038988, 0.3625664, 0.1920838, 0.20553428, 0.2060581, 0.115243204, 0.19584164, 0.17686222, 0.2278483, 0.18134327, 0.21756569, 0.3833429, 0.16821449, 0.2611387, 0.25259924, 0.2367284, 0.16510886, 0.2132382, 0.48030922, 0.16021235, 0.48602444, 0.17639185, 0.69938725, 0.124491826, 0.22939864, 0.25570187, 0.26844388, 0.16887562, 0.17602111, 0.17066132, 0.19655485, 0.21739756, 0.284198, 0.18541986, 0.16502632, 0.21645486, 0.1767691, 0.22009853, 0.18728675, 0.16120073, 0.17437556, 0.1800467, 0.2505056, 0.2148566, 0.25290382, 0.20201601, 0.24155161, 0.200955, 0.41046116, 0.19400847, 0.19516134, 0.38819528, 0.19045612, 0.59716874, 0.3617791, 0.16201697, 0.16592664, 0.083686784, 0.20497014, 0.107707545, 0.12594937, 0.1891035, 0.0894503, 0.11644549, 0.15445197, 0.14624262, 0.11546576, 0.09748815, 0.1157993, 0.10199306, 0.123059675, 0.13111857, 0.082794115, 0.00020181901, 0.12377395, 0.12917389, 0.112141185, 0.11623528, 0.14134605, 0.11109595, 0.09634243, 0.088891596, 0.12956774, 0.1371084, 0.10656691, 0.12871346, 0.103076406, 0.10075875, 0.13080223, 0.11143884, 0.10821557, 0.122093976, 0.119123064, 0.10083039, 0.09725858, 0.13780265, 0.13585036, 0.08453715, 0.07771241, 0.11344858, 0.106988676, 0.10036438, 0.09647457, 0.103289284, 0.107802376, 0.100842305, 0.09613785, 0.090591446, 0.12776493, 0.08778468, 0.096558146, 0.09524512, 0.106254235, 0.11924203, 0.13315037, 0.11764215, 0.13226983, 0.10544176, 0.10418878, 0.12542711, 0.09100673, 0.120517775, 0.09861601, 0.1061775, 0.11405462, 0.11121674, 0.1275268, 0.111860946, 0.13436331, 0.12429624, 0.1318532, 0.105714455, 0.13921097, 0.049767923, 0.035121273, 0.109865695, 0.108065456, 0.10487517, 0.08382876, 0.07160356, 0.03356102, 0.04816706, 0.0435124, 0.13456808, 0.100383796, 0.054664165, 0.11842945, 0.21530022, 0.14963825, 0.13835482, 0.1813473, 0.1694991, 0.13452083, 0.14584312, 0.11334342, 0.16521548, 0.08945903, 0.16058317, 0.16084616, 0.14587905, 0.1490322, 0.1870439, 0.14260118, 0.13194071, 0.08848251, 0.15867597, 0.18613075, 0.095682904, 0.10909437, 0.13321275, 0.09819939, 0.14404322, 0.22554503, 0.1149783, 0.14879598, 0.14096157, 0.10193225, 0.11134939, 0.13625643, 0.15240748, 0.113819845, 0.0994609, 0.12658206, 0.022916924, 0.15052836, 0.13778515, 0.17798074, 0.18406281, 0.1354066, 0.12112394, 0.16418934, 0.14348333, 0.11926552, 0.12018344, 0.13433741, 0.1509154, 0.16458209, 0.16345274, 0.15564895, 0.14401647, 0.1620744, 0.21769056, 0.21023646, 0.13066432, 0.3080215, 0.13850525, 0.2277453, 0.31487226, 0.17906226, 0.24832302, 0.23881967, 0.26020765, 0.19567676, 0.2284107, 0.2561031, 0.23474503, 0.1322358, 0.14589249, 0.12046619, 0.17264087, 0.1820526, 0.17375293, 0.15176232, 0.048729107, 0.03419931, 0.093909696, 0.021414915, 0.0027924133, 0.013367871, 0.1225988, 0.10070645, 0.1370526, 0.11635645, 0.12288808, 0.1476293, 0.18338174, 0.17259274, 0.13070834, 0.14513429, 0.18414697, 0.13315004, 0.13739915, 0.15843637, 0.12643515, 0.15243201, 0.12377825, 0.1062177, 0.1276114, 0.12597711, 0.121056095, 0.12820803, 0.1316704, 0.11949918, 0.1147348, 0.15107106, 0.13487445, 0.15588322, 0.1574684, 0.14335304, 0.123281196, 0.14268868, 0.1657097, 0.1759696, 0.2092896, 0.18799919, 0.17478235, 0.16385207, 0.19940552, 0.14186175, 0.14497593, 0.1362329, 0.124884635, 0.13942865, 0.11319195, 0.15941702, 0.13209385, 0.13363798, 0.1308386, 0.12963358, 0.12699609, 0.113531955, 0.09773695, 0.12896103, 0.14099708, 0.14674965, 0.12636633, 0.12424879, 0.14933762, 0.13716312, 0.13621593, 0.16542213, 0.1658586, 0.16120705, 0.12308461, 0.13722566, 0.14515243, 0.13973556, 0.13404745, 0.14509287, 0.13612784, 0.13704944, 0.11592426, 0.111098066, 0.12155405, 0.13708207, 0.15381323, 0.1542703, 0.151704, 0.13585314, 0.12743662, 0.11502654, 0.12882578, 0.21831022, 0.12961291, 0.15118952, 0.042926725, 0.070907876, 0.17251533, 0.106427565, 0.04248631, 0.07031812, 0.045962904, 0.2810933, 0.13336979, 0.07963259, 0.40483278, 0.33273968, 0.4663562, 0.49442598, 0.35628852, 0.2750392, 0.4377953, 0.48769888, 0.35075772, 0.3636416, 0.35010156, 0.4122988, 0.47377682, 0.4677402, 0.37967426, 0.42955065, 0.38923836, 0.35228515, 0.2814925, 0.3392738, 0.35521474, 0.4213458, 0.40429804, 0.381764, 0.37485114, 0.31253943, 0.27007723, 0.29297602, 0.41612846, 0.059227146, 0.43621644, 0.37543687, 0.3662541, 0.3697048, 1.4703693e-06, 0.15935072, 0.34957457, 0.2695778, 0.32096097, 0.23474038, 0.31080276, 0.3044543, 0.33639374, 0.40315822, 0.4239282, 0.4272513, 0.41776398, 0.41373622, 0.37246308, 0.36767662, 0.37068057, 0.42555878, 0.36699542, 0.329008, 0.40526447, 0.35259396, 0.30221862, 0.3270352, 0.30522126, 0.3232915, 0.3618119, 0.28904146, 0.3964947, 0.26807922, 0.21932296, 0.390462, 0.42383537, 0.396015, 0.32421324, 0.42131206, 0.40147558, 0.3807977, 0.3358895, 0.4332068, 0.40779173, 0.1300674, 0.07119541, 0.24995638, 0.20600162, 0.23693696, 0.19940716, 0.20173742, 0.3293514, 0.32982996, 0.33816648, 0.12609516, 0.33621642, 0.3673277, 0.21017802, 0.2556139, 0.31007776, 0.28629595, 0.1937276, 0.32114977, 0.28682533, 0.1873251, 0.24777925, 0.24645081, 0.27711472, 0.2591866, 0.32920346, 0.3100158, 0.31228817, 0.33949703, 0.3596182, 0.28662825, 0.3058133, 0.3442795, 0.33530965, 0.321382, 0.24015263, 0.29600832, 0.34406954, 0.34265757, 0.36983335, 0.34873417, 0.36021286, 0.33111897, 0.35319522, 0.34202373, 0.2503213, 0.32816958, 0.30866936, 0.26056886, 0.29359803, 0.3384775, 0.2820523, 0.30697697, 0.3003739, 0.29259458, 0.2119531, 0.32241628, 0.28275716, 0.30121866, 0.3142391, 0.2977858, 0.32803804, 0.2722448, 0.30008882, 0.20221454, 0.29621518, 0.018705573, 0.1914622, 0.21444386, 0.27222303, 0.30834708, 0.29431254, 0.2811097, 0.29542682, 0.31900322, 0.25799784, 0.30480132, 0.2979905, 0.072006345, 0.31279337, 0.29211986, 0.27902964, 0.3275492, 0.28342307, 0.11183724, 0.21686955, 0.11603035, 0.17376356, 0.16389881, 0.14005265, 0.1328333, 0.19841659, 0.2673907, 0.49699855, 0.6044586, 0.2755056, 0.25565186, 0.24860568, 0.20527513, 0.18341565, 0.22411457, 0.2528197, 0.25153628, 0.5131442, 0.19039738, 0.20420434, 0.39852905, 0.0675194, 0.30497378, 0.38775417, 0.3754394, 0.2314063, 0.31616542, 0.3267948, 0.26242584, 0.3500238, 0.31993523, 0.3842165, 0.3234139, 0.3168954, 0.3808772, 0.3647411, 0.54530567, 0.22916028, 0.27549934, 0.3053413, 0.32036328, 0.31473324, 0.66548586, 0.3522426, 0.36470562, 0.37098417, 0.31543306, 0.26854128, 0.52910125, 0.24564339, 0.2235347, 0.13001174, 0.16115515, 0.25397727, 0.22198153, 0.48518887, 0.18112136, 0.2293035, 0.26004878, 0.22208968, 0.21549791, 0.25806296, 0.15881892, 0.20931323, 0.29194835, 0.23147093, 0.22578567, 0.8065416, 0.21366625, 0.22777799, 0.24715105, 0.6557107, 0.24435385, 0.7004627, 0.80441463, 0.3644418, 0.09817938, 0.13496731, 0.113756575, 0.029871931, 0.21171668, 0.15394475, 0.470576, 0.2662575, 0.20614064, 0.2917089]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "testloader =  DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "labels = []\n",
    "preds = []\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "for i, (x, y) in enumerate(testloader):\n",
    "    #Forward pass of image through network\n",
    "    fx = model(x.to(device))\n",
    "    labels.append(y.numpy()[0][0])\n",
    "    preds.append(fx.cpu().detach().numpy()[0][0])\n",
    "    for k in range(len(y)):\n",
    "        if (np.round(fx[k].cpu().detach()) ==1 and y[k] == 1):\n",
    "            tp += 1\n",
    "        elif (np.round(fx[k].cpu().detach()) ==0 and y[k] == 0):\n",
    "            tn += 1\n",
    "        elif (np.round(fx[k].cpu().detach()) ==1 and y[k] ==0):\n",
    "            fp += 1\n",
    "        elif (np.round(fx[k].cpu().detach()) ==0 and y[k] ==1):\n",
    "            fn += 1\n",
    "\n",
    "print(labels)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
    "    data1     = np.asarray(data1)\n",
    "    data2     = np.asarray(data2)\n",
    "    mean      = np.mean([data1, data2], axis=0)\n",
    "    diff      = data1 - data2                   # Difference between data1 and data2\n",
    "    md        = np.mean(diff)                   # Mean of the difference\n",
    "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
    "\n",
    "    plt.scatter(mean, diff, *args, **kwargs)\n",
    "    plt.axhline(md,           color='gray', linestyle='--')\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
    "\n",
    "bland_altman_plot(labels, preds)\n",
    "plt.title('Bland-Altman Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 25\n",
      "196 467\n",
      "0.2647058823529412 0.04390243902439024\n"
     ]
    }
   ],
   "source": [
    "print(tp, fp)\n",
    "print(fn, tn)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(precision, recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
